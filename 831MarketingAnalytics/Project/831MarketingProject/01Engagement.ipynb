{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Gordon\n",
    "\n",
    "Student Name\tStudent Number\n",
    " Alisha Sahota\t20497348\n",
    " Anthony Ramelo\t20499391\n",
    " Chris Wu\t10182394\n",
    " Elizabeth Zhang\t20161231\n",
    " Emily Zhao\t10096273\n",
    " Sam Hossain\t20466500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed engagement data saved to 'output_engagement/processed_engagement_data.xlsx'.\n",
      "Engagement model data saved to 'output_engagement/engagement_model_data.xlsx'.\n",
      "\n",
      "Training Logistic Regression for Engagement...\n",
      "\n",
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83        32\n",
      "           1       0.84      0.81      0.83        32\n",
      "\n",
      "    accuracy                           0.83        64\n",
      "   macro avg       0.83      0.83      0.83        64\n",
      "weighted avg       0.83      0.83      0.83        64\n",
      "\n",
      "AUC (Logistic Regression): 0.92\n",
      "\n",
      "Training Random Forest for Engagement...\n",
      "\n",
      "Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.75      0.84        32\n",
      "           1       0.79      0.97      0.87        32\n",
      "\n",
      "    accuracy                           0.86        64\n",
      "   macro avg       0.88      0.86      0.86        64\n",
      "weighted avg       0.88      0.86      0.86        64\n",
      "\n",
      "AUC (Random Forest): 0.92\n",
      "\n",
      "Training XGBoost for Engagement...\n",
      "\n",
      "XGBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83        32\n",
      "           1       0.81      0.91      0.85        32\n",
      "\n",
      "    accuracy                           0.84        64\n",
      "   macro avg       0.85      0.84      0.84        64\n",
      "weighted avg       0.85      0.84      0.84        64\n",
      "\n",
      "AUC (XGBoost): 0.88\n",
      "Engagement predictions saved to 'output_engagement/engagement_predictions.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Constants\n",
    "OUTPUT_DIR = 'output_engagement'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "CURRENT_YEAR = datetime.now().year\n",
    "\n",
    "# Functions\n",
    "\n",
    "def load_data(file_path, sheet_name):\n",
    "    \"\"\"\n",
    "    Load data from an Excel file and strip whitespace from column names.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "def ensure_column_exists(df, column_name, alternative_names=None):\n",
    "    \"\"\"\n",
    "    Ensure a specific column exists in the DataFrame, possibly under alternative names.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        return column_name\n",
    "    if alternative_names:\n",
    "        for alt_name in alternative_names:\n",
    "            if alt_name in df.columns:\n",
    "                df.rename(columns={alt_name: column_name}, inplace=True)\n",
    "                return column_name\n",
    "    raise ValueError(f\"Column '{column_name}' or alternatives {alternative_names} not found.\")\n",
    "\n",
    "def create_engagement_features(df):\n",
    "    \"\"\"\n",
    "    Create engagement-related features for analysis.\n",
    "    \"\"\"\n",
    "    # Avoid division by zero\n",
    "    df['Average total activities per month'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # Engagement Metrics\n",
    "    df['Consistency_Score'] = df['Average activities per day'] / df['Average total activities per month']\n",
    "    df['Engagement_Regularity'] = df['Consistency_Score'] * df['Average activities per day']\n",
    "    df['Activity_Diversity'] = df[['Quiz Count', 'Mood Count', 'Inspiration Count']].gt(0).sum(axis=1)\n",
    "    \n",
    "    # Handle infinite and missing values\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def derive_engagement_level(df):\n",
    "    \"\"\"\n",
    "    Derive 'Engagement_Level' feature.\n",
    "    \"\"\"\n",
    "    if 'Consistency_Score' in df.columns:\n",
    "        median_consistency = df['Consistency_Score'].median()\n",
    "        df['Engagement_Level'] = (df['Consistency_Score'] >= median_consistency).astype(int)\n",
    "    else:\n",
    "        print(\"Warning: 'Consistency_Score' not found. Cannot derive 'Engagement_Level'.\")\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the dataset by replacing infinities and NaN values with the median.\n",
    "    \"\"\"\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    return df.fillna(df.median())\n",
    "\n",
    "def create_model_dataset(df):\n",
    "    \"\"\"\n",
    "    Create dataset for engagement prediction.\n",
    "    \"\"\"\n",
    "    # Engagement features\n",
    "    engagement_features = [\n",
    "        'Mood Count',\n",
    "        'Consistency_Score',\n",
    "        'Engagement_Regularity',\n",
    "        'Activity_Diversity',\n",
    "        'Total Activities'\n",
    "    ]\n",
    "    engagement_features = [feat for feat in engagement_features if feat in df.columns]\n",
    "\n",
    "    if 'Engagement_Level' in df.columns:\n",
    "        # Include 'ID' in the dataset\n",
    "        engagement_data = df[['ID'] + engagement_features + ['Engagement_Level']]\n",
    "        output_path = os.path.join(OUTPUT_DIR, 'engagement_model_data.xlsx')\n",
    "        engagement_data.to_excel(output_path, index=False)\n",
    "        print(f\"Engagement model data saved to '{output_path}'.\")\n",
    "    else:\n",
    "        print(\"Warning: 'Engagement_Level' not found. Engagement model data not created.\")\n",
    "\n",
    "def train_engagement_model():\n",
    "    \"\"\"\n",
    "    Train models to predict engagement levels and evaluate their performance.\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    data_path = os.path.join(OUTPUT_DIR, 'engagement_model_data.xlsx')\n",
    "    data = pd.read_excel(data_path)\n",
    "\n",
    "    # Define features and target\n",
    "    engagement_features = [\n",
    "        'Mood Count',\n",
    "        'Engagement_Regularity',\n",
    "        'Activity_Diversity',\n",
    "        'Total Activities'\n",
    "    ]\n",
    "    X = data[engagement_features]\n",
    "    y = data['Engagement_Level']\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Clean data\n",
    "    X_train = clean_data(X_train)\n",
    "    X_test = clean_data(X_test)\n",
    "\n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train Logistic Regression\n",
    "    print(\"\\nTraining Logistic Regression for Engagement...\")\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    y_pred_lr = lr.predict(X_test_scaled)\n",
    "    print(\"\\nLogistic Regression Report:\")\n",
    "    print(classification_report(y_test, y_pred_lr))\n",
    "    print(f\"AUC (Logistic Regression): {roc_auc_score(y_test, lr.predict_proba(X_test_scaled)[:, 1]):.2f}\")\n",
    "\n",
    "    # Train Random Forest\n",
    "    print(\"\\nTraining Random Forest for Engagement...\")\n",
    "    rf = RandomForestClassifier(max_depth=5, n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    y_pred_rf = rf.predict(X_test_scaled)\n",
    "    print(\"\\nRandom Forest Report:\")\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "    print(f\"AUC (Random Forest): {roc_auc_score(y_test, rf.predict_proba(X_test_scaled)[:, 1]):.2f}\")\n",
    "\n",
    "    # Train XGBoost\n",
    "    print(\"\\nTraining XGBoost for Engagement...\")\n",
    "    xgb = XGBClassifier(learning_rate=0.01, max_depth=3, n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "    xgb.fit(X_train_scaled, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test_scaled)\n",
    "    print(\"\\nXGBoost Report:\")\n",
    "    print(classification_report(y_test, y_pred_xgb))\n",
    "    print(f\"AUC (XGBoost): {roc_auc_score(y_test, xgb.predict_proba(X_test_scaled)[:, 1]):.2f}\")\n",
    "\n",
    "    # Feature importance for Random Forest\n",
    "    feature_importances = pd.Series(rf.feature_importances_, index=engagement_features).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    feature_importances.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Feature Importances (Random Forest) - Engagement')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'engagement_feature_importances.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save predictions for analysis\n",
    "    results = pd.DataFrame({\n",
    "        'Actual': y_test,\n",
    "        'Logistic Regression': y_pred_lr,\n",
    "        'Random Forest': y_pred_rf,\n",
    "        'XGBoost': y_pred_xgb\n",
    "    })\n",
    "    predictions_output_path = os.path.join(OUTPUT_DIR, 'engagement_predictions.xlsx')\n",
    "    results.to_excel(predictions_output_path, index=False)\n",
    "    print(f\"Engagement predictions saved to '{predictions_output_path}'.\")\n",
    "\n",
    "# Main Execution\n",
    "\n",
    "def main():\n",
    "    file_path = 'Input/Data 3 - October, 2024.xlsx'  # Update with your data file path\n",
    "    sheet_name = 'Parachute - Cross Section'  # Update with your sheet name\n",
    "\n",
    "    # Load data\n",
    "    df = load_data(file_path, sheet_name)\n",
    "\n",
    "    # Ensure 'Total Activities' column exists\n",
    "    total_activities_col = ensure_column_exists(df, 'Total Activities', alternative_names=['Total Activities '])\n",
    "\n",
    "    # Create engagement features\n",
    "    df = create_engagement_features(df)\n",
    "\n",
    "    # Derive engagement level\n",
    "    df = derive_engagement_level(df)\n",
    "\n",
    "    # Save processed data\n",
    "    processed_output_path = os.path.join(OUTPUT_DIR, 'processed_engagement_data.xlsx')\n",
    "    df.to_excel(processed_output_path, index=False)\n",
    "    print(f\"Processed engagement data saved to '{processed_output_path}'.\")\n",
    "\n",
    "    # Create dataset for model\n",
    "    create_model_dataset(df)\n",
    "\n",
    "    # Train and evaluate the engagement model\n",
    "    train_engagement_model()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
