{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Grocery Store data again, however this time we will break it into ‘Train’ and ‘Test’ pieces. Test & train is a technique used to validate against overfitting, and to test how your model might perform in the real world. It is also good practice for using a regression to predict point estimates for an entire data set.\n",
    "\n",
    "**An aside**: when doing AI/ML modelling, you often use three data sets: Train, Test, and Validation. In this case, the model is built on the train data, tested the first time on test data, and then the hyperparameters (hidden layers) are set using the validation data set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test and train data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 1 to 1000\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Grocery_Bill       1000 non-null   float64\n",
      " 1   Family_Income      1000 non-null   int64  \n",
      " 2   Family_Size        1000 non-null   int64  \n",
      " 3   N_Vehicles         1000 non-null   int64  \n",
      " 4   Distance_to_Store  1000 non-null   int64  \n",
      " 5   Vegetarian         1000 non-null   int64  \n",
      " 6   N_Children         1000 non-null   int64  \n",
      " 7   Family_Pet         1000 non-null   int64  \n",
      " 8   N_Adults           1000 non-null   int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 78.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Import Grocery Data\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import curdir\n",
    "import os\n",
    "db_dir = os.getcwd()\n",
    "data_path = db_dir+r\"/MMA 860 Assessing and Testing Data File v1.0.xlsx\"\n",
    "path = os.path.join(db_dir,\"MMA_860_Grocery_Data.xlsx\")\n",
    "data = pd.read_excel(path,index_col=\"Obs\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X to be all values except Grocery_Bill and vice-versa for y\n",
    "X = data.drop(columns=['Grocery_Bill']).values\n",
    "y = data['Grocery_Bill'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the size of your dataset you can evaluate how large a test set is practical. The larger the dataset, the larger your test data can be. In this case, we will use 30% for testing, and 70% for training. This is probably a good rule of thumb. Create these datasets under the names ‘test’ and ‘train’.\n",
    "\n",
    "Note: there are three important things to keep in mind:\n",
    "1. Test and train sets must be mutually exclusive (i.e., no overlapping data)\n",
    "2. Test and train sets must contain the same pattern of data (i.e., you should same randomly)\n",
    "3. If you have time series data, you should always test on the most recent data\n",
    "\n",
    "To sample randomly without replacement, you could use the following code. It will take a 70% train sample and a 30% test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scikit learn has a built-in function for splitting data into training \n",
    "and testing datasets. Here we specify the X array, y array and train_size.\n",
    "Setting a random_state makes our results reproducible.\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,train_size=0.95,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model and assess it against training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ‘predict’ function in Scikit allows you to use the linear regression model to predict values (in this case, the grocery bill). You can choose the dataset on which you would like to predict. The resulting array will contain the predicted values. The code looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262.41981708 244.14842476 161.06001771 359.33041906 314.33413183]\n"
     ]
    }
   ],
   "source": [
    "#I have suppressed the output to the first 5 numbers only\n",
    "#For the whole array, remove the appended '[0:5]'\n",
    "print(reg.predict(X_test)[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m----> 2\u001b[0m df\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "df = reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test & train comparisons, you will now have to calculate some of the statistics we use to validate model accuracy: the $R^2$ for test data, RMSE (Root Mean Squared Error), and MAE (Mean Absolute Error). To calculate these we will need to import some additional functions from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from numpy import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.8404041993105258\n",
      "Root Mean Squared Error: 32.480212602686365\n",
      "Mean Absolute Error: 24.13530406132895\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2:\",reg.score(X_train,y_train))\n",
    "print(\"Root Mean Squared Error:\",sqrt(\n",
    "    mean_squared_error(y_train,reg.predict(X_train))))\n",
    "print(\"Mean Absolute Error:\",mean_absolute_error(\n",
    "    y_train,reg.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.809299990434026\n",
      "Root Mean Squared Error: 32.96557232660774\n",
      "Mean Absolute Error: 22.109161070999065\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2:\",reg.score(X_test,y_test))\n",
    "print(\"Root Mean Squared Error:\",sqrt(\n",
    "    mean_squared_error(y_test,reg.predict(X_test))))\n",
    "print(\"Mean Absolute Error:\",mean_absolute_error(\n",
    "    y_test,reg.predict(X_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare our $R^2$ values and RMSEs directly. RMSE tends to be a more reliable measure of fit, especially when you would like to penalize large errors. Usually, we expect our model to perform worse on the test set. In this case, model performance is very similar – this is a good thing! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
